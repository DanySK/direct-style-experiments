[{"id":0,"href":"/PPS-22-direct-style-experiments/docs/01-boundaries/","title":"01 Boundaries","section":"Docs","content":" boundary / break # Source code\nProvides a cleaner alternative to non-local returns; boundary: is short for boundary.apply: with the indented code below it passed as the body block is a context function that is called within boundary.apply to return the block of code shown in the example\nUsers don’t define Label instances themselves. Instead, this is done inside the implementation of boundary.apply to provide the capability of doing a non-local return.\n/** Run `body` with freshly generated label as implicit argument. Catch any * breaks associated with that label and return their results instead of * `body`\u0026#39;s result. */ inline def apply[T](inline body: Label[T] ?=\u0026gt; T): T = val local = Label[T]() try body(using local) catch case ex: Break[T] @unchecked =\u0026gt; if ex.label eq local then ex.value else throw ex we don’t want users to call break without an enclosing boundary. That’s why break requires an in-scope given instance of Label, which the implementation of boundary.apply creates before it calls the code block you provide. If your code block calls break, a given Label will be in-scope. non-localbreaks are logically implemented as non-fatal exceptions and the implementation is optimized to suppress unnecessary stack trace generation. Stack traces are unnecessary because we are handling these exceptions, not barfing them on the user! optimizations: Better performance is provided when a break occurs to the enclosing scope inside the same method (i.e., the same stack frame), where it can be rewritten to a jump call. What can we do with boundary and break mechanism? # Optional # object optional: inline def apply[T](inline body: Label[None.type] ?=\u0026gt; T): Option[T] = boundary(Some(body)) extension [T](o: Option[T]) inline def ?(using label: Label[None.type]): T = o.getOrElse(break(None)) Rust-like Result + ? # object result: sealed trait Result[+T] case class Ok[+T](t: T) extends Result[T] case class Error(e: String) extends Result[Nothing] inline def apply[T](inline body: Label[Error] ?=\u0026gt; T): Result[T] = boundary(Ok(body)) extension [T](r: Result[T]) inline def ?(using Label[Error]): T = r match case Ok(t) =\u0026gt; t case e @ Error(_) =\u0026gt; break(e) Either + ? # object either: inline def apply[L, R](inline body: Label[Left[L, Nothing]] ?=\u0026gt; R): Either[L, R] = boundary(Right(body)) extension [L, R](e: Either[L, R]) inline def ?(using Label[Left[L, Nothing]]): R = e match case Right(value) =\u0026gt; value case Left(value) =\u0026gt; break(Left(value)) "},{"id":1,"href":"/PPS-22-direct-style-experiments/docs/02-basics/","title":"02 Basics","section":"Docs","content":" Basic asynchronous constructs # The need for a new Future construct # The current implementation of the Future monadic construct suffers the following main cons:\nLack of referential transparency; Lack of cancellation mechanisms and structured concurrency; Accidental Sequentiality. To show these weaknesses in practice, a simple example of the core of a web service implementation is presented.\nExample: a blog posts service # Idea: develop a very simple (mocked) service which allows to retrieve and store from a repository blog posts, performing checks on the content and author before the actual storage. The example has been implemented using:\nthe continuation style through the current Scala Future monadic constructs; the direct style, through: the abstractions offered by gears; Kotlin coroutines. The example (and every subsequent one) is organized in three gradle submodules:\nblog-ws-commons contains code which has been reused for both the monadic and direct versions; a submodule blog-ws-monadic with the monadic Scala style and blog-ws-direct for the direct versions, both in Kotlin with coroutines and in Scala with gears. Structure # The domain is modelled using abstract data types in a common PostsModel trait:\ntrait PostsModel: type AuthorId type Title type Body type PostContent = (Title, Body) /** A blog post, comprising of an author, title, body and the information about last modification. */ case class Post(author: Author, title: Title, body: Body, lastModification: Date) /** A post author and their info. */ case class Author(authorId: AuthorId, name: String, surname: String) /** A function that verifies the content of the post, * returning [[Right]] with the content of the post if the * verification succeeds or [[Left]] with the reason why failed. */ type ContentVerifier = (Title, Body) =\u0026gt; Either[String, PostContent] type AuthorsVerifier = AuthorId =\u0026gt; Author To implement the service two components have been conceived, following the Cake Pattern:\nPostsRepositoryComponent exposes the Repository trait allowing to store and retrieve blog posts; mocks a DB technology with an in-memory collection. PostsServiceComponent is the component exposing the Service interface. is the component that would be called by the controller of the ReSTful web service. Both must be designed in an async way.\nCurrent monadic Future # The interface of the repository and services component of the monadic version are presented hereafter and their complete implementation is available here.\n/** The component exposing blog posts repositories. */ trait PostsRepositoryComponent: context: PostsModel =\u0026gt; /** The repository instance. */ val repository: PostsRepository /** The repository in charge of storing and retrieving blog posts. */ trait PostsRepository: /** Save the given [[post]]. */ def save(post: Post)(using ExecutionContext): Future[Post] /** Return a future completed with true if a post exists with the given title, false otherwise. */ def exists(postTitle: Title)(using ExecutionContext): Future[Boolean] /** Load all the saved post. */ def load(postTitle: Title)(using ExecutionContext): Future[Option[Post]] /** Load the post with the given [[postTitle]]. */ def loadAll()(using ExecutionContext): Future[LazyList[Post]] /** The component blog posts service. */ trait PostsServiceComponent: context: PostsRepositoryComponent with PostsModel =\u0026gt; /** The blog post service instance. */ val service: PostsService /** The service exposing a set of functionalities to interact with blog posts. */ trait PostsService: /** Creates a new blog post with the given [[title]] and [[body]], authored by [[authorId]]. */ def create(authorId: AuthorId, title: Title, body: Body)(using ExecutionContext): Future[Post] /** Get a post from its [[title]]. */ def get(title: Title)(using ExecutionContext): Future[Post] /** Gets all the stored blog posts in a lazy manner. */ def all()(using ExecutionContext): Future[LazyList[Post]] All the exposed functions, since they are asynchronous, returns an instance of Future[T] and requires to be called in a scope where a given instance of the ExecutionContext is declared.\nWhat\u0026rsquo;s important to delve into is the implementation of the service, and, more precisely, of the create method. As already mentioned, before saving the post two checks needs to be performed:\nthe post author must have permissions to publish a post and their information needs to be retrieved (supposing they are managed by another microservice); the content of the post is analyzed in order to prevent the storage and publication of offensive or non-appropriate contents. Since these operations are independent from each other they can be spawned and run in parallel.\noverride def create(authorId: AuthorId, title: Title, body: Body)(using ExecutionContext): Future[Post] = for exists \u0026lt;- context.repository.exists(title) if !exists post \u0026lt;- save(authorId, title, body) yield post private def save(authorId: AuthorId, title: Title, body: Body)(using ExecutionContext): Future[Post] = val authorAsync = authorBy(authorId) val contentAsync = verifyContent(title, body) for content \u0026lt;- contentAsync author \u0026lt;- authorAsync post = Post(author, content._1, content._2, Date()) _ \u0026lt;- context.repository.save(post) yield post This implementation shows the limits of the current monadic Future mechanism:\nif we want to achieve the serialization of future\u0026rsquo;s execution we need to compose them using the flatMap, like in the create function: first the check on the post existence is performed, and only if it successful and another post with same title doesn\u0026rsquo;t exists the save function is started\nas a consequence, if we want two futures to run in parallel we have to spawn them before the for-yield, as in the save function, or use Future\u0026rsquo;s Applicative, like mapN provided by Cats. This is error prone and could lead to unexpected sequentiality for non experted Scala programmers, like this:\nfor content \u0026lt;- verifyContent(title, body) author \u0026lt;- authorBy(authorId) post = Post(author, content._1, content._2, Date()) _ \u0026lt;- context.repository.save(post) yield post since the publication of a post can be performed only if both of these checks succeeds, it is desirable that, whenever one of the two fails, the other get cancelled. Unfortunately, currently, Scala Futures are not cancellable and provides no structured concurrency mechanism.\nmoreover, they lack referential transparency, i.e. future starts running when they are defined. This mean that passing a reference to a future is not the same as passing the referenced expression.\nDirect style: Scala version with gears # The API of the gears library is presented hereafter and is built on top of four main abstractions, three of them are here presented (the fourth in next example):\nAsync context is \u0026ldquo;a capability that allows a computation to suspend while waiting for the result of an async source\u0026rdquo;. Code that has access to an instance of the Async trait is said to be in an async context and it is able to suspend its execution. Usually it is provided via given instances. A common way to obtain an Async instance is to use an Async.blocking. Async.Source modeling an asynchronous source of data that can be polled or awaited by suspending the computation, as well as composed using combinator functions. Futures are the primary (in fact, the only) active elements that encapsulate a control flow that, eventually, will deliver a result (either a computed or a failure value that contains an exception). Since Futures are Async.Sources they can be awaited and combined with other Futures, suspending their execution. Tasks are the abstraction created to create delayed Futures, responding to the lack of referential transparency problem. They takes the body of a Future as an argument; its run method converts that body to a Future, starting its execution. Promises allows to define Future\u0026rsquo;s result value externally, instead of executing a specific body of code. classDiagram class Async { \u003c\u003c trait \u003e\u003e +group: CompletionGroup +withGroup(group: CompletionGroup) Async +await[T](src: Async.Source[T]) T +current() Async$ +blocking[T](body: Async ?=\u003e T) T$ +group[T](body: Async ?=\u003e T) T$ } class `Async.Source[+T]` { \u003c\u003c trait \u003e\u003e +poll(k: Listener[T]) Boolean +poll() Option[T] +onComplete(k: Listener[T]) +dropListener(k: Listener[T]) +awaitResult() T } Async *--\u003e `Async.Source[+T]` class OriginalSource { \u003c\u003c abstract class \u003e\u003e } `Async.Source[+T]` \u003c|-- OriginalSource class `Listener[-T]` { \u003c\u003c trait \u003e\u003e +lock: Listener.ListenerLock | Null +complete(data: T, source: Async.Source[T]) +completeNow(data: T, source: Async.Source[T]) Boolean +apply[T](consumer: (T, Source[T]) =\u003e Unit) Listener[T]$ } `Async.Source[+T]` *--\u003e `Listener[-T]` class `Future[+T]` { \u003c\u003c trait \u003e\u003e +apply[T](body: Async ?=\u003e T) Future[T]$ +now[T](result: Try[T]) Future[T] +zip[U](f2: Future[U]) Future[T, U] +alt(f2: Future[T]) Future[T] +altWithCancel(f2: Future[T]) Future[T] } class `Promise[+T]` { \u003c\u003c trait \u003e\u003e +asFuture Future[T] +complete(result: Try[T]) } OriginalSource \u003c|-- `Future[+T]` `Future[+T]` \u003c|-- `Promise[+T]` class `Task[+T]` { +apply(body: (Async, AsyncOperations) ?=\u003e T) Task[T]$ +run(using Async, AsyncOperations) Future[+T] } `Future[+T]` \u003c--* `Task[+T]` class Cancellable { \u003c\u003c trait \u003e\u003e +group: CompletionGroup +cancel() +link(group: CompletionGroup) +unlink() } Cancellable \u003c|-- `Future[+T]` class Tracking { \u003c\u003c trait \u003e\u003e +isCancelled Boolean } Cancellable \u003c|-- Tracking class CompletionGroup { +add(member: Cancellable) +drop(member: Cancellable) } Tracking \u003c|-- CompletionGroup Async *--\u003e CompletionGroup Going back to our example, the interface of both the repository and service components becomes:\n/** The component exposing blog posts repositories. */ trait PostsRepositoryComponent: context: PostsModel =\u0026gt; /** The repository instance. */ val repository: PostsRepository /** The repository in charge of storing and retrieving blog posts. */ trait PostsRepository: /** Save the given [[post]]. */ def save(post: Post)(using Async): Post /** Return true if a post exists with the given title, false otherwise. */ def exists(postTitle: Title)(using Async): Boolean /** Load the post with the given [[postTitle]]. */ def load(postTitle: Title)(using Async): Option[Post] /** Load all the saved post. */ def loadAll()(using Async): LazyList[Post] /** The blog posts service component. */ trait PostsServiceComponent: context: PostsRepositoryComponent with PostsModel =\u0026gt; /** The blog post service instance. */ val service: PostsService /** The service exposing a set of functionalities to interact with blog posts. */ trait PostsService: /** Creates a new blog post with the given [[title]] and [[body]], authored by [[authorId]], or a string explaining * the reason of the failure. */ def create(authorId: AuthorId, title: Title, body: Body)(using Async): Either[String, Post] /** Get a post from its [[title]] or a string explaining the reason of the failure. */ def get(title: Title)(using Async): Either[String, Post] /** Gets all the stored blog posts in a lazy manner or a string explaining the reason of the failure. */ def all()(using Async): Either[String, LazyList[Post]] As you can see, Futures are gone and the return type it\u0026rsquo;s just the result of their intent (expressed with Either to return a meaningful message in case of failure). The fact they are suspendable is expressed by means of the Async context, which is required to invoke those function.\nKey inspiring principle (actually, \u0026ldquo;stolen\u0026rdquo; by Kotlin)\n❝Concurrency is hard! Concurrency has to be explicit!❞\nBy default the code is serial. If you want to opt-in concurrency you have to explicitly use a Future or Task spawning a new control flow that executes asynchronously, allowing the caller to continue its execution.\nThe other important key feature of the library is the support to structured concurrency and cancellation mechanisms:\nFutures are Cancellable instances;\nWhen you cancel a future using the cancel() method, it promptly sets its value to Failure(CancellationException). Additionally, if it\u0026rsquo;s a runnable future, the thread associated with it is interrupted using Thread.interrupt().\nto avoid the immediate cancellation, deferring the cancellation after some block is possible using uninterruptible function:\nval f = Future { // this can be interrupted uninterruptible { // this cannot be interrupted *immediately* } // this can be interrupted } Futures are nestable; it is assured that the lifetime of nested computations is contained within the lifetime of enclosing ones. This is achieved using CompletionGroups, which are cancellable objects themselves and serves as containers for other cancellable objects, that once cancelled, all of its members are cancelled as well.\nA cancellable object can be included inside the cancellation group of the async context using the link method; this is what the implementation of the Future does, under the hood. The implementation of the create function with direct style in gears looks like this:\noverride def create(authorId: AuthorId, title: Title, body: Body)(using Async): Either[String, Post] = if context.repository.exists(title) then Left(s\u0026#34;A post entitled $title already exists\u0026#34;) else either: val f = Future: val content = verifyContent(title, body).run // spawning a new Future val author = authorBy(authorId).run // spawninig a new Future content.zip(author).await val (post, author) = f.awaitResult.? context.repository.save(Post(author, post.?._1, post.?._2, Date())) /* Pretending to make a call to the Authorship Service that keeps track of authorized authors. */ private def authorBy(id: AuthorId): Task[Author] = ??? /* Some local computation that verifies the content of the post is appropriate (e.g. not offensive, ...). */ private def verifyContent(title: Title, body: Body): Task[Either[String, PostContent]] = ??? Some remarks:\nthe either boundary have been used to quickly return a Right[String, Post] object in case something goes wrong; authorBy and verifyContent returns referential transparent Task instances. Running them, spawns a new Future instance; Thanks to structured concurrency and zip combinator we can obtain that if one of the nested two futures fails the enclosing future is cancelled, cancelling also all its unterminated children zip: combinator function returning a pair with the results if both Futures succeed, otherwise fail with the failure that was returned first. Be aware of the fact to achieve cancellation is necessary to enclose both the content verification and authorization task inside an enclosing Future, since the zip doesn\u0026rsquo;t provide cancellation mechanism per se. The following code wouldn\u0026rsquo;t work as expected! val contentVerifier = verifyContent(title, body).run val authorizer = authorBy(authorId).run val (post, author) = contentVerifier.zip(authorizer).awaitResult.? Other combinator methods, available on Futures instance:\nCombinator Goal Future[T].zip(Future[U]) Parallel composition of two futures. If both futures succeed, succeed with their values in a pair. Otherwise, fail with the failure that was returned first Future[T].alt(Future[T]) / Seq[Future[T]].altAll Alternative parallel composition. If either task succeeds, succeed with the success that was returned first. Otherwise, fail with the failure that was returned last (race all futures). Future[T].altWithCancel(Future[T]) / Seq[Future[T]].altAllWithCancel Like alt but the slower future is cancelled. Seq[Future[T]].awaitAll .await for all futures in the sequence, returns the results in a sequence, or throws if any futures fail. Seq[Future[T]].awaitAllOrCancel Like awaitAll, but cancels all futures as soon as one of them fails. TO FINISH\ntests\nkotlin coroutines\nw.r.t. kotlin coroutines:\n\u0026ldquo;Finally, about function coloring: Capabilities are actually much better here than other language\u0026rsquo;s proposals such as suspend or async which feel clunky in comparison. This becomes obvious when you consider higher order functions. Capabilities let us define a single map (with no change in signature compared to now!) that works for sync as well as async function arguments. That\u0026rsquo;s the real breakthrough here, which will make everything work so much smoother. I have talked about this elsewhere and this response is already very long, so I will leave it at that.\u0026rdquo; how suspension is implemented\nConclusions # "},{"id":2,"href":"/PPS-22-direct-style-experiments/docs/03-channels/","title":"03 Channels","section":"Docs","content":" Channels as a communication primitive # The fourth, yet not mentioned, abstraction of both Kotlin Coroutines and Scala Gears is the channel. Channels represent the primitive communication and coordination means to exchange Future results. They are, at least conceptually, very similar to a queue where it is possible to send (and receive) data \u0026ndash; basically, exploiting the producer-consumer pattern.\nclassDiagram class `SendableChannel[-T]` { \u003c\u003c trait \u003e\u003e +sendSource(x: T) Async.Source[Either[Closed, Unit]] +send(x: T)(using Async) Unit } class `ReadableChannel[+T]` { \u003c\u003c trait \u003e\u003e +readSource Async.Source[Either[Closed, T]] +read()(using Async) Either[Closed, T] } class `Channel[T]` { \u003c\u003c trait \u003e\u003e +asSendable: SendableChannel[T] +asReadable: ReadableChannel[T] +asCloseable: java.io.Closeable } namespace java io { class Closeable { \u003c\u003c interface \u003e\u003e +close() } } `SendableChannel[-T]` \u003c|-- `Channel[T]` Closeable \u003c|-- `Channel[T]` `ReadableChannel[+T]` \u003c|-- `Channel[T]` The channel is defined through three distinct interfaces: SendableChannel[-T], ReadableChannel[+T] and Channel[T], where the latter extends from both SendableChannel and ReadableChannel. Typically, a Channel is created and a SendableChannel and ReadableChannel instances are respectively provided to the producer and the consumer, restricting their access to it. The same design is present also in Kotlin Coroutines.\nMoreover, Channel inherits from java.io.Closable, making them closable objects: once closed, they raise ChannelClosedException when attempting to write to it and immediately return a Failure(ChannelClosedException) when attempting to read from it.\nThree types of channels exist:\nSynchronous Channels: links a read request with a send request within a rendezvous send (read) suspend the process until a consumer read (send) the value; Buffered Channels: a version of a channel with an internal buffer of fixed size send suspend the producer process if it is full; otherwise, it appends the value to the buffer, returning immediately; read suspend if the channel is empty, waiting for a new value. Unbounded Channels: a version of a channel with an unbounded buffer if the programs run out of memory you can get an out-of-memory exception! Multiple producers can send data to the channel, as well as multiple consumers can read them, but each element is handled only once, by one of them, i.e. consumers compete with each other for sent values. Once the element is handled, it is immediately removed from the channel.\nGitHub organization analyzer example # To show channels in action an example has been prepared:\nIdea: we want to realize a little asynchronous library allowing clients to collect the common statistics about repositories (issues, stars, last release) and contributors of a given GitHub organization. Final result:\nAs usual, the example has been implemented using monadic Futures, as well as Scala gears and Kotlin Coroutines.\nAnalyzer and App Controller # The direct version in Scala gears exposes the following interface, taking in input an organization name and a function through which is possible to react to results while they are computed.\ntrait Analyzer: def analyze(organizationName: String)( updateResults: RepositoryReport =\u0026gt; Unit, )(using Async): Either[String, Seq[RepositoryReport]] object Analyzer: def ofGitHub: Analyzer = GitHubAnalyzer() private class GitHubAnalyzer extends Analyzer: private val gitHubService = GitHubService() override def analyze(organizationName: String)( updateResults: RepositoryReport =\u0026gt; Unit, )(using Async): Either[String, Seq[RepositoryReport]] = either: val reposInfo = gitHubService .repositoriesOf(organizationName).? // 1 .map(_.performAnalysis) // 2 val collector = Collector[RepositoryReport](reposInfo.toList*) // 3 for _ \u0026lt;- reposInfo.indices do updateResults(collector.results.read().tryable.?.awaitResult.?) // 4 reposInfo.map(_.await) extension (r: Repository) private def performAnalysis(using Async): Future[RepositoryReport] = ??? first, we get all the repositories of the requested organization for each of them, the contributors and the last release are retrieved concurrently, starting a Future Future results are gathered inside a Collector that collects a list of futures into a channel of futures, arriving as they finish. read results from the channel as they come, calling the updateResult reaction function. The application controller just takes care of running the application view and, whenever a new analysis starts, creates a new future, during which the single reports are aggregated and the UI is updated. Thanks to the fact Futures are cancellable objects, whenever desired is possible to cancel the current computation.\nprivate class DirectAppController(using Async) extends AppController: private val view = AnalyzerView.gui(this) private val analyzer = Analyzer.ofGitHub private var currentComputation: Option[Future[Unit]] = None view.run() override def runSession(organizationName: String): Unit = var organizationReport: OrganizationReport = (Map(), Set()) val f = Future: analyzer.analyze(organizationName) { report =\u0026gt; organizationReport = (organizationReport._1.aggregatedTo(report), organizationReport._2 + report) view.update(organizationReport) } match { case Left(e) =\u0026gt; view.error(e); case Right(_) =\u0026gt; view.endComputation() } currentComputation = Some(f) override def stopSession(): Unit = currentComputation.foreach(_.cancel()) extension (m: Map[String, Long]) private def aggregatedTo(report: RepositoryReport): Map[String, Long] = m ++ report.contributions.map(c =\u0026gt; c.user -\u0026gt; (m.getOrElse(c.user, 0L) + c.contributions)) The Kotlin version with Coroutines is pretty identical to the Gears one.\nGitHub service # One point of difference between the two frameworks is, however, how the GitHubService can be implemented, regarding the case where, not just a single, but a multitude of values, are expected.\nIndeed, the GitHub API, like many ReSTful APIs, implements pagination: if the response includes many results, they are paginated, returning a subset of them; it is the responsibility of the client to request more data (pages).\nThis can lead to performance issues if the service is implemented to return the whole results in one shot. It would be desirable, instead, to start performing the analysis as soon as one page is obtained from the API.\nKotlin Coroutines offers, for this purpose, the abstraction of Flows, which are conceptually very similar to cold Observables in reactive programming.\nWith respect to reactive programming, they are still quite less reach in terms of operators.\nChannels in Kotlin (w.r.t. gears) fairness (also in Gears?) pipeline (not supported in Gears) better closable Conclusions # "},{"id":3,"href":"/PPS-22-direct-style-experiments/docs/04-rears/","title":"04 Rears","section":"Docs","content":" An attempt to bring reactivity principles in gears # So far, we\u0026rsquo;ve explored the basics of asynchronous abstraction mechanisms provided by the direct style of the Scala Gears and Kotlin Coroutines frameworks.\nThe goal of this last example is to investigate, using a simple example, whether these two frameworks offers sufficient idiomatic abstractions to deal with reactive-like systems.\nSmart Hub System example # Idea: in an IoT context a multitude of sensors of different types, each replicated to ensure accurate measurements, transmit their measurements to a central hub, which in turns needs to react, in real-time, forwarding to the appropriate controller the data, possibly running some kind of transformation, enabling controllers to make decisions based on their respective logic. Scala Gears version # Before delving into the example, two abstractions of Gears, yet not covered, are introduced:\nTasks provide a way, not only to run asynchronous computation, essentially wrapping a Future, but also to schedule it, possibly repeating it. Different scheduling strategies are available: Every, ExponentialBackoff, FibonacciBackoff, RepeatUntilFailure, RepeatUntilSuccess. This allows implementing easily proactive like systems, like a game loop. classDiagram class `Task[+T]` { +apply(body: (Async, AsyncOperations) ?=\u003e T) Task[T]$ +run(using Async, AsyncOperations) Future[+T] +schedule(s: TaskSchedule) Task[T] } `Task[+T]` o--\u003e TaskSchedule class TaskSchedule { \u003c\u003c enum \u003e\u003e + Every(millis: Long, maxRepetitions: Long = 0) + ExponentialBackoff(millis: Long, exponentialBase: Int = 2, maxRepetitions: Long = 0) + FibonacciBackoff(millis: Long, maxRepetitions: Long = 0) + RepeatUntilFailure(millis: Long = 0, maxRepetitions: Long = 0) + RepeatUntilSuccess(millis: Long = 0, maxRepetitions: Long = 0) } To avoid the work stealing behavior of channels consumers, a ChannelMultiplexer can be used. It is essentially a container of producing and consuming channels, which can be added and removed at runtime. Internally, it is implemented with a thread that continuously races the set of publishers and once it reads a value, it forwards it to each subscriber channel. Order is guaranteed only per producer; Typically, the consumer creates a channel and adds it to the multiplexer, then start reading from it, possibly using a scheduled task. if the consumer attaches the channel after the producer started, the values sent during this interval are lost, like hot observables in Rx. classDiagram namespace javaio { class Closeable { \u003c\u003c interface \u003e\u003e +close() } } class `ChannelMultiplexer[T]` { \u003c\u003c trait \u003e\u003e +run()(using Async) +addPublisher(c: ReadableChannel[T]) +removePublisher(c: ReadableChannel[T]) +addSubscriber(c: SendableChannel[Try[T]]) +removeSubscriber(c: SendableChannel[Try[T]]) } Closeable \u003c|-- `ChannelMultiplexer[T]` In the proposed strawman Scala Gears library, there are no other kind of abstractions, neither a way to manipulate channels with functions inspired by Rx.\nThe attempt was to somehow extend this framework adding first class support for the concept of Producer and Consumer and implement some of the most common Rx operators, just as a proof of concept, completely leaving out performances concerns.\n[Sources can be found in the rears submodule]\n/** A publisher, i.e. a runnable active entity producing items on a channel. */ trait Publisher[E]: /** The [[Channel]] to send items to. */ protected val channel: Channel[E] = UnboundedChannel() /** @return a runnable [[Task]]. */ def asRunnable: Task[Unit] /** @return a [[ReadableChannel]] where produced items are placed. */ def publishingChannel: ReadableChannel[E] = channel.asReadable /** A consumer, i.e. a runnable active entity devoted to consuming data from a channel. */ trait Consumer[E]: /** The [[SendableChannel]] to send items to. */ val listeningChannel: SendableChannel[Try[E]] = UnboundedChannel() /** @return a runnable [[Task]]. */ def asRunnable: Task[Unit] = Task { listeningChannel.asInstanceOf[Channel[Try[E]]].read().foreach(react) }.schedule(RepeatUntilFailure()) /** The suspendable reaction triggered upon a new read of an item succeeds. */ protected def react(e: Try[E])(using Async): Unit /** A mixin to make consumers stateful. */ trait State[E]: consumer: Consumer[E] =\u0026gt; private var _state: Option[E] = None def state: Option[E] = synchronized(_state) override def asRunnable: Task[Unit] = Task { listeningChannel.asInstanceOf[Channel[Try[E]]].read().foreach { e =\u0026gt; react(e) synchronized { _state = e.toOption } } }.schedule(RepeatUntilFailure()) object Controller: def oneToMany[T, R]( publisherChannel: ReadableChannel[T], consumers: Set[Consumer[R]], transformation: PipelineTransformation[T, R] = identity, ): Task[Unit] = Task: val multiplexer = ChannelMultiplexer[R]() consumers.foreach(c =\u0026gt; multiplexer.addSubscriber(c.listeningChannel)) multiplexer.addPublisher(transformation(publisherChannel)) // blocking call: the virtual thread on top of which this task is // executed needs to block to continue publishing publisher\u0026#39;s events // towards the consumer by means of the multiplexer. multiplexer.run() Implemented transformation functions:\nfilter debounce groupBy buffer bufferWithin Pay attention to: Async ?=\u0026gt;\nGoing back to the example, here is presented a schema summarizing the proposed design of the system.\nKotlin Coroutines version # Conclusions # "},{"id":4,"href":"/PPS-22-direct-style-experiments/docs/05-conclusions/","title":"05 Conclusions","section":"Docs","content":" Going further and conclusions # "}]